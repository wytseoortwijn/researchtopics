\chapter{Introduction}
This document contains a project plan for the graduation project of Wytse Oortwijn. This project attempts to implement BDD operations for multicore clusters by using a PGAS programming model in combination with RDMA. 

\section{Project Title}
RDMA-Based Implementation of BDD Operations for Multicore Clusters.

\section{Project Committee}
The proposed project committe consists of the following members.
\begin{itemize}
	\item prof.dr. J.C. van de Pol
	\item dr. S.C.C. Blom
	\item T. van Dijk MSc
\end{itemize}

\section{Keywords}
Multi-core programming, Distributed programming, Binary Decision Diagrams, Performance, High Performance Computing, Heterogeneous programming.

\section{Abstract}
Model checking can be used to check if the model of a software system meets its requirements. A model checker can be implemented in various ways, one of which is symbolically. Rather than explicitly maintaining states, a symbolic model checker stores the state space as a Boolean formula, represented as a Binary Decision Diagram (BDD). The advantage of using BDDs is that a small Boolean formula can potentially represent a large number of states, thus giving an efficient representation of the state space. Another advantage is that BDDs directly support operations like unions, intersections, and existential quantification. These operations can directly be used to build symbolic model checking algorithms.

BDD operations have already been successfully parallelized. For example Sylvan, which is a parallel BDD package created at the University of Twente, obtained speedups up to 38 on a 48-core cluster. On the other hand, distributed BDD manipulation has been less successful, mainly because the network latency easily becomes a bottleneck.

Hardware changed significantly during the last decade. At the time of writing, parallel hardware is widely available and specialized high performance network interconnects like Infiniband are just as affordable as their Ethernet counterparts. One of the features of Infiniband is Remote Direct Memory Access (RDMA), which allowes direct access to the memory of a remote machine, without invoking its CPU. Experiments show that many one-sided RDMA operations have a latency of about $2 \mu s$, which is an order of magnitude lower compared to the same operations performed with traditional TCP.

This justifies a renewed attempt to parallelize and distribute BDD operations. The goal of this research project is to implement BDD operations that perform well both in parallel and distributed environments. In the ideal case, the implementation scales well both across the number of CPU cores and the number of participating machines.

\section{Structure}
In chapter two the motivation and relevance of the research project is discussed. In chapter three a detailed approach is given, including research questions and project goals. Chapter four contains the project planning and chapter five a detailed plan of measurement. The experimental setup is also given. In chapter six, research expectations are discussed.

The last four chapters contain background information and explain concepts introduced in the first fix chapters. More specifically, chapter seven gives information about network communication and, in particular, about Infiniband and RDMA. Chapter eight discusses parallel programming models and load-balancing techniques. Chapter nine discusses hash tables and hashing schemes. Special hashing schemes are discussed that minimize the number of memory accesses. Finally, chapter ten discusses background information on BDDs. Here implementation details are given, both for sequential and parallel BDD operations. Also garbage collection strategies are discussed. 